<!DOCTYPE html>
<html lang="en">
    <head>
        <meta charset="UTF-8">
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        <title>Conversation: Premise vs Implications - First Principles</title>
        <link rel="stylesheet" href="../post.css">
        <link rel="icon" href="logo.png" type="image/png">
    </head>

    <body>
        <header class="header minimized">
            <h1 class="header-title">
                <a href="../index.html">First Principles</a>
            </h1>
        </header>

        <main class="blog-post">
            <h1>Conversation: Premise vs Implications</h1>
            <div class="date">May 25, 2025</div>
            <div class="author"><i>Tanush Chopra, Michael Li</i></div>

            <div class="content">
                <p>A conversation between two friends about Noam Chomsky's
                    views
                    on ChatGPT and what it means for AI and
                    intelligence.<label
                        for="sn-chomsky-context"
                        class="margin-toggle sidenote-number"></label>
                    <input type="checkbox" id="sn-chomsky-context"
                        class="margin-toggle" />
                    <span class="sidenote">Chomsky jump scare :o</span></p>

                <div class="conversation">
                    <div class="message"><strong>Michael</strong> <span
                            class="timestamp">— 5/25/25, 12:25
                            PM</span><br><a
                            href="https://chomsky.info/20230503-2/"
                            target="_blank">https://chomsky.info/20230503-2/</a></div>

                    <div class="message"><strong>Tanush</strong> <span
                            class="timestamp">— 5/25/25, 12:26
                            PM</span><br>Good
                        takes?</div>

                    <div class="message"><strong>Michael</strong> <span
                            class="timestamp">— 5/25/25, 12:27
                            PM</span><br>Yeah
                        his main take is that ChatGPT is obviously better at
                        humans by certain definitions, but also people who
                        claim
                        we've solved intelligence aren't right cause LLMs
                        don't
                        give us useful insights into intelligence since
                        they're
                        very hard to reverse engineer and interpret<br>I
                        haven't
                        read the entire thing yet<br>Also I see people say
                        that
                        Chomsky is out of touch, but based on this he
                        clearly is
                        not</div>

                    <div class="message"><strong>Michael</strong> <span
                            class="timestamp">— 5/25/25, 12:28
                            PM</span><br>He
                        mentions protein folding models for example</div>

                    <div class="message"><strong>Tanush</strong> <span
                            class="timestamp">— 5/25/25, 12:28
                            PM</span><br>Protein folding models as examples
                        of
                        good AI?</div>

                    <div class="message"><strong>Michael</strong> <span
                            class="timestamp">— 5/25/25, 12:28
                            PM</span><br>As
                        an example of AI that is useful for science</div>

                    <div class="message"><strong>Tanush</strong> <span
                            class="timestamp">— 5/25/25, 12:29
                            PM</span><br>Well
                        people say he's out of touch because of a comment he
                        said when gpt was first released</div>

                    <div class="message"><strong>Michael</strong> <span
                            class="timestamp">— 5/25/25, 12:29
                            PM</span><br>What
                        did he say</div>

                    <div class="message"><strong>Tanush</strong> <span
                            class="timestamp">— 5/25/25, 12:29
                            PM</span><br>He
                        said GPT is nothing more than a statistical
                        approximation of next word tokens and it's not
                        really
                        intelligent</div>

                    <div class="message"><strong>Tanush</strong> <span
                            class="timestamp">— 5/25/25, 12:30
                            PM</span><br>Which tbf still holds true</div>

                    <div class="message"><strong>Michael</strong> <span
                            class="timestamp">— 5/25/25, 12:30
                            PM</span><br>Yeah
                        that's true<br>But I guess people thought he meant
                        that
                        it wasn't useful?</div>

                    <div class="message"><strong>Tanush</strong> <span
                            class="timestamp">— 5/25/25, 12:30
                            PM</span><br>Yeah<br>Even an approximation for
                        human
                        language is still hella powerful</div>

                    <div class="message"><strong>Michael</strong> <span
                            class="timestamp">— 5/25/25, 12:30
                            PM</span><br>Yeah
                        he def makes a point to mention that AI is useful in
                        this interview, especially what he calls AI
                        engineering</div>

                    <div class="message"><strong>Michael</strong> <span
                            class="timestamp">— 5/25/25, 12:34
                            PM</span><br>Thought this was new, this is
                        actually
                        from 2023</div>

                    <div class="message"><strong>Tanush</strong> <span
                            class="timestamp">— 5/25/25, 12:35
                            PM</span><br>I
                        don't think anyone's doubting that LLMs are useful.
                        What
                        we're doubting is how useful it is. If it's the case
                        that LLMs by being approximations of human cognition
                        (by
                        proxy of being approximations of language) then that
                        means it can do a shit ton more than if it's just
                        approximations for human language.</div>

                    <div class="message"><strong>Tanush</strong> <span
                            class="timestamp">— 5/25/25, 12:36
                            PM</span><br>At
                        that point it's a neuroscience issue as we don't
                        know
                        how humans generate language or how we
                        think<br>Hence we
                        don't know if this model is an accurate model</div>

                    <div class="message"><strong>Michael</strong> <span
                            class="timestamp">— 5/25/25, 12:36
                            PM</span><br>This
                        is where Noam would disagree, relevant quote from
                        article:<br>"It's true that chatbots cannot in principle match the linguistic competence of humans, for the reasons repeated above. Their basic design prevents them from reaching the minimal condition of adequacy for a theory of human language: distinguishing possible from impossible languages. Since that is a property of the design, it cannot be overcome by future innovations in this kind of AI. However, it is quite possible that future engineering projects will match and even surpass human capabilities, if we mean human capacity to act, performance. As mentioned above, some have long done so: automatic calculators for example. More interestingly, as mentioned, insects with minuscule brains surpass human capacities understood as competence."<br>E.g
                        LLMs aren't learning good models of language</div>

                    <div class="message"><strong>Michael</strong> <span
                            class="timestamp">— 5/25/25, 12:37
                            PM</span><br>What's interesting is that doesn't
                        prevent them from being incredibly useful</div>

                    <div class="message"><strong>Tanush</strong> <span
                            class="timestamp">— 5/25/25, 12:38
                            PM</span><br>I
                        would argue we're not talking about the same thing.
                        I'm
                        not saying whether it's a good model of language.
                        I'm
                        saying it's a model of human language and trying to
                        explain the opinion regarding the relationship
                        between
                        human language and cognition while he's arguing
                        about
                        whether it's even a good model of human
                        language.</div>

                    <div class="message"><strong>Michael</strong> <span
                            class="timestamp">— 5/25/25, 12:38
                            PM</span><br>How
                        is language and human language different<br>Language
                        is
                        man made?</div>

                    <div class="message"><strong>Tanush</strong> <span
                            class="timestamp">— 5/25/25, 12:39
                            PM</span><br>I'm
                        just elucidating the opinions regarding language vs
                        cognition</div>

                    <div class="message"><strong>Michael</strong> <span
                            class="timestamp">— 5/25/25, 12:39
                            PM</span><br>What
                        I'm saying is that Noam would disagree with the
                        premise
                        that LLMs learn models of language</div>

                    <div class="message"><strong>Tanush</strong> <span
                            class="timestamp">— 5/25/25, 12:39
                            PM</span><br>Not
                        really worrying about the premise</div>

                    <div class="message"><strong>Tanush</strong> <span
                            class="timestamp">— 5/25/25, 12:40
                            PM</span><br>He's
                        focused on premise while I'm focused on the
                        implications
                        of if the premise holds</div>

                    <div class="message"><strong>Michael</strong> <span
                            class="timestamp">— 5/25/25, 12:40
                            PM</span><br>Yeah<br>I don't see what the
                        confusion
                        is</div>

                    <div class="message"><strong>Tanush</strong> <span
                            class="timestamp">— 5/25/25, 12:41
                            PM</span><br>I
                        don't know if it is tbh but like BPE it's good
                        enough<br>The confusion is whether a good
                        approximation
                        for human language is also a good approximation for
                        human thought<br>That's where a large schism in the
                        community comes from</div>

                    <div class="message"><strong>Michael</strong> <span
                            class="timestamp">— 5/25/25, 12:42
                            PM</span><br>Yeah
                        I agree with that</div>

                    <div class="message"><strong>Michael</strong> <span
                            class="timestamp">— 5/25/25, 12:43
                            PM</span><br>But
                        I think you and Noam are talking about the same
                        thing
                        broadly, since the premise is involved in both, like
                        you
                        can't leave out discussion of whether the premise is
                        likely when discussing implications of that
                        premise</div>

                    <div class="message"><strong>Tanush</strong> <span
                            class="timestamp">— 5/25/25, 12:44
                            PM</span><br>Well
                        I think you can discuss the case of the premise
                        being
                        true and false without necessarily discussing the
                        likelihood of the premise being true or not</div>

                    <div class="message"><strong>Michael</strong> <span
                            class="timestamp">— 5/25/25, 12:48
                            PM</span><br>What
                        they (linguists) thought back in 2020<br><a
                            href="https://aclanthology.org/2020.acl-main.463.pdf"
                            target="_blank">https://aclanthology.org/2020.acl-main.463.pdf</a></div>

                    <div class="message"><strong>Michael</strong> <span
                            class="timestamp">— 5/25/25, 12:49
                            PM</span><br>From
                        Emily bender</div>

                    <div class="message"><strong>Tanush</strong> <span
                            class="timestamp">— 5/25/25, 12:49
                            PM</span><br>It's
                        a weird debate because they aren't talking about the
                        same thing really<br>One is a debate over the
                        likelihood
                        of the premise<br>And the other is a debate over
                        what
                        happens if the premise is true</div>

                    <div class="message"><strong>Tanush</strong> <span
                            class="timestamp">— 5/25/25, 12:50
                            PM</span><br>In
                        debate those should be 2 separate debates</div>

                    <div class="message"><strong>Michael</strong> <span
                            class="timestamp">— 5/25/25, 12:50
                            PM</span><br>Yeah
                        but they have some bearing on each other, like
                        epistemically why care about the second debate if
                        the
                        first debate is happening<br>It's very confusing I
                        ageee<br>They basically talk past each other</div>
                </div>
            </div>
        </main>

        <script src="../image-modal.js"></script>
    </body>
</html>
